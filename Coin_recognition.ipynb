{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2LeM7wPB5znG3eDiwR/Ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-osiris/my-new-pern-app/blob/main/Coin_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm52upFG5z5Q"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install scikit-learn\n",
        "!pip install opencv-python-headless\n",
        "!pip install joblib\n",
        "!pip install scikit-image\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import all dependencies\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import time\n",
        "\n",
        "print(\"Setup complete. Libraries installed and Google Drive mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_from_drive(drive_path='/content/drive/MyDrive/Indian-Coin-Currency-Dataset'):\n",
        "    \"\"\"\n",
        "    Loads images and labels from a Google Drive folder.\n",
        "    Handles FileNotFoundError gracefully.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    try:\n",
        "        class_names = sorted([d for d in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, d))])\n",
        "\n",
        "        if not class_names:\n",
        "            print(\"Error: No subdirectories found in the dataset path. Make sure your dataset is in folders per class.\")\n",
        "            return images, labels, class_names\n",
        "\n",
        "        print(\"Found the following classes:\", class_names)\n",
        "\n",
        "        for class_name in class_names:\n",
        "            class_path = os.path.join(drive_path, class_name)\n",
        "            for img_name in os.listdir(class_path):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(class_path, img_name)\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is not None:\n",
        "                        images.append(img)\n",
        "                        labels.append(class_name)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The directory '{drive_path}' was not found. Please check the path and try again.\")\n",
        "        return images, labels, []\n",
        "\n",
        "    return images, labels, class_names\n",
        "\n",
        "def preprocess_image(img):\n",
        "    \"\"\"\n",
        "    Using Image Representation & Preprocessing (Unit I)\n",
        "    Converts image to grayscale, applies a Gaussian filter, and Otsu's thresholding.\n",
        "    \"\"\"\n",
        "    if img is None or img.size == 0:\n",
        "        return None, None\n",
        "\n",
        "    # Resize for consistency\n",
        "    resized_img = cv2.resize(img, (200, 200), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Grayscale Conversion\n",
        "    gray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Gaussian Filter for noise reduction\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Binary Images: Otsu's Thresholding\n",
        "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    return resized_img, binary\n",
        "\n",
        "def extract_features(original_img, binary_img):\n",
        "    \"\"\"\n",
        "    Using Shape and Texture Features (Unit I)\n",
        "    Extracts shape and texture features from an image.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Shape features\n",
        "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Find the largest contour, assumed to be the coin\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        perimeter = cv2.arcLength(largest_contour, True)\n",
        "\n",
        "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
        "\n",
        "        (x, y), radius = cv2.minEnclosingCircle(largest_contour)\n",
        "\n",
        "        features.extend([area, perimeter, circularity, radius])\n",
        "    else:\n",
        "        features.extend([0, 0, 0, 0])\n",
        "\n",
        "    # Texture features (GLCM)\n",
        "    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute GLCM\n",
        "    glcm = graycomatrix(gray, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "\n",
        "    # Extract GLCM properties\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "\n",
        "    features.extend([contrast, homogeneity, energy])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def train_model(X, y):\n",
        "    \"\"\"\n",
        "    Using PCA and Classifier (Unit II)\n",
        "    Applies PCA and trains a k-NN classifier.\n",
        "    Returns the trained model and PCA components.\n",
        "    \"\"\"\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Apply PCA for dimensionality reduction\n",
        "    pca = PCA(n_components=0.95)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # Train k-NN classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train_pca, y_train)\n",
        "\n",
        "    # Evaluate and print results\n",
        "    y_pred = knn.predict(X_test_pca)\n",
        "    print(\"Static Test Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Save the model and PCA scaler\n",
        "    joblib.dump(knn, 'knn_model.joblib')\n",
        "    joblib.dump(scaler, 'scaler.joblib')\n",
        "    joblib.dump(pca, 'pca.joblib')\n",
        "\n",
        "    return knn, scaler, pca\n",
        "\n",
        "def predict_coin(img, model, scaler, pca):\n",
        "    \"\"\"Preprocesses a single image and predicts the coin class.\"\"\"\n",
        "    preprocessed_img, binary_img = preprocess_image(img)\n",
        "    if preprocessed_img is None:\n",
        "        return \"No coin detected\", 0.0\n",
        "\n",
        "    features = extract_features(preprocessed_img, binary_img)\n",
        "\n",
        "    # Reshape and scale\n",
        "    features_scaled = scaler.transform(features.reshape(1, -1))\n",
        "\n",
        "    # Apply PCA\n",
        "    features_pca = pca.transform(features_scaled)\n",
        "\n",
        "    # Predict and get probabilities\n",
        "    prediction = model.predict(features_pca)[0]\n",
        "    probabilities = model.predict_proba(features_pca)[0]\n",
        "    confidence = np.max(probabilities)\n",
        "\n",
        "    return prediction, confidence"
      ],
      "metadata": {
        "id": "lM0I3T6r53Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Step 1: Dataset Handling\n",
        "    print(\"Loading dataset from Google Drive...\")\n",
        "    images, labels, class_names = load_dataset_from_drive()\n",
        "    print(f\"Found {len(images)} images across {len(class_names)} classes.\")\n",
        "\n",
        "    if not images:\n",
        "        print(\"No images found. Please check your dataset path and file contents.\")\n",
        "    else:\n",
        "        # Step 2: Feature Extraction\n",
        "        print(\"Extracting features from images...\")\n",
        "        X = []\n",
        "        y = []\n",
        "        for img, label in zip(images, labels):\n",
        "            preprocessed_img, binary_img = preprocess_image(img)\n",
        "            if preprocessed_img is not None:\n",
        "                features = extract_features(preprocessed_img, binary_img)\n",
        "                X.append(features)\n",
        "                y.append(label)\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        # Step 3: Model Training\n",
        "        print(\"Training model...\")\n",
        "        knn_model, scaler, pca = train_model(X, y)\n",
        "        print(\"Model trained and saved to disk.\")"
      ],
      "metadata": {
        "id": "jgCifYjY50zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def predict_uploaded_image():\n",
        "    \"\"\"Prompts user to upload an image and predicts the coin class.\"\"\"\n",
        "\n",
        "    # Load saved models\n",
        "    try:\n",
        "        knn = joblib.load('knn_model.joblib')\n",
        "        scaler = joblib.load('scaler.joblib')\n",
        "        pca = joblib.load('pca.joblib')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Models not found. Please run the training script in Cell 3 first.\")\n",
        "        return\n",
        "\n",
        "    print(\"Please upload an image file of a coin...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No file was uploaded.\")\n",
        "        return\n",
        "\n",
        "    # Process each uploaded file\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Processing '{filename}'...\")\n",
        "\n",
        "        # Read image from uploaded bytes\n",
        "        img_bytes = uploaded[filename]\n",
        "        np_arr = np.frombuffer(img_bytes, np.uint8)\n",
        "        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Error: Could not decode image from '{filename}'.\")\n",
        "            continue\n",
        "\n",
        "        # Predict the coin\n",
        "        prediction, confidence = predict_coin(img, knn, scaler, pca)\n",
        "\n",
        "        # Overlay the prediction on the image\n",
        "        label = f\"Prediction: {prediction} (Confidence: {confidence:.2f})\"\n",
        "        cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the result\n",
        "        print(label)\n",
        "        _, jpeg = cv2.imencode('.jpg', img)\n",
        "        display(Image(data=jpeg.tobytes()))\n",
        "\n",
        "# Run the static image test\n",
        "predict_uploaded_image()"
      ],
      "metadata": {
        "id": "3P_bHNDO6J7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}